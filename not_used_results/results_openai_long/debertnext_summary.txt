## Summary of “DeBERTNeXT: A Multimodal Fake News Detection Framework”

**Goal:**  
The paper proposes **DeBERTNeXT**, a **multimodal** (text + image) fake news detection model aimed at improving binary classification (fake vs. real) by better leveraging both modalities—an area where many prior works either focus on text only or use older multimodal backbones.

### Core idea / Architecture
DeBERTNeXT is a transfer-learning fusion model with two pretrained components:
- **Text encoder:** **DeBERTa-v3 base** (Transformer) to produce a **768-d** text representation from tokenized text (input IDs + attention masks).
- **Image encoder:** **ConvNeXT Large** (ConvNet pretrained on ImageNet). The original classifier head is replaced; the model outputs **1536-d**, then a new dense layer maps it to **1024-d**.

**Fusion & classification:**
- Concatenate text (768) + image (1024) → **1792-d** vector
- Feed into a final dense layer with **sigmoid** activation for **binary prediction**.

### Data and preprocessing
They train/evaluate on three datasets:
- **Fakeddit:** large-scale; after downloading/filtering images, they use **154,644** usable multimodal records.
- **Politifact:** **304** usable records (small).
- **Gossipcop:** **8,008** usable records.

Processing includes:
- Image crawling from URLs; filtering broken/distorted/GIF images.
- Images resized to **224×224** and normalized during training.
- Text cleaning mainly removes URLs; transformer tokenization with truncation:
  - Max text length: **48** (Fakeddit), **32** (Politifact/Gossipcop).

### Training setup (high level)
- Train/validation split: **80/20**, test held out separately (20%).
- **Batch size 16**.
- Optimizer: **AdamW** with weight decay (excluding normalization layers/biases).
- Learning rates: ~**3e-6** (Fakeddit) and **2.5e-6** (Politifact/Gossipcop).
- Epochs: **4** (Fakeddit), **6** (Politifact/Gossipcop).

### Results (main takeaway)
DeBERTNeXT reports state-of-the-art improvements versus compared multimodal baselines:

- **Fakeddit:** **Accuracy 0.912**, outperforming prior best listed (e.g., FakeNED at 0.878) by about **+3.8%** absolute accuracy.
- **Politifact:** **Accuracy 0.913**, about **+2.1%** over strong prior results reported in the table.
- **Gossipcop:** **Accuracy 0.902**, about **+1.0%** improvement.

They also report strong precision/recall/F1 and compare against models like SpotFake(+), EANN, MVAE, SAFE, and others.

### Conclusion and future work
The paper concludes that combining **DeBERTa-v3** (better text representations than many earlier transformer choices) with **ConvNeXT** (stronger modern vision backbone than VGG-style models) yields better multimodal fake news classification. Future work includes extending to additional modalities such as **audio and video** for an “all-modal” detection framework.