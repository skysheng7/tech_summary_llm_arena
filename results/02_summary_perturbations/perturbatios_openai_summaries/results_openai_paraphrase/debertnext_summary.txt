Here are a few paraphrased versions of the summary, each with different wording and sentence structure while retaining all original information:

**Paraphrase 1:**

A novel framework for detecting fake news, termed DeBERTNeXT, operates by analyzing both the textual content of an article and its associated image to make a real or fake classification. This system generates text embeddings using the DeBERTa V3 transformer and image embeddings via a ConvNeXT Large model. These extracted features are then combined and fed into a final sigmoid classifier. The researchers trained and assessed DeBERTNeXT on the extensive Fakeddit dataset, as well as the more compact Politifact and Gossipcop datasets, employing transfer learning and a uniform preprocessing methodology for both images and tokenized text. The results show DeBERTNeXT outperforming previous multimodal approaches, with accuracy gains of approximately 3.8% on Fakeddit, 2.1% on Politifact, and 1.0% on Gossipcop. The authors' findings indicate that integrating advanced, contemporary language and vision models leads to more proficient multimodal fake news detection, and they propose expanding this methodology to encompass other media types such as audio and video.

**Paraphrase 2:**

DeBERTNeXT is a framework designed for multimodal fake news detection, capable of distinguishing between real and fabricated news by simultaneously processing an article's text and its accompanying image. The framework obtains text representations through the DeBERTa V3 transformer and image representations from a ConvNeXT Large model. These distinct features are then concatenated and passed to a sigmoid classifier for the final classification. The study involved training and evaluating DeBERTNeXT on the substantial Fakeddit dataset, along with the smaller Politifact and Gossipcop datasets, utilizing transfer learning and a standardized preprocessing pipeline for both image and tokenized text data. DeBERTNeXT demonstrates superior performance compared to existing multimodal baselines, achieving accuracy improvements of roughly 3.8% on Fakeddit, 2.1% on Politifact, and 1.0% on Gossipcop. The paper's conclusion is that the integration of robust, modern backbones for both language and vision enhances the effectiveness of multimodal fake news detection, and the authors suggest its application to other modalities like audio and video.

**Paraphrase 3:**

To classify news as either genuine or fake, the DeBERTNeXT multimodal fake news detection framework leverages the combined information from an article's text and its accompanying image. It extracts textual features using the DeBERTa V3 transformer and visual features using a ConvNeXT Large model. These representations are then fused and subjected to a sigmoid classifier. The authors conducted training and evaluation of the model on the large Fakeddit dataset, as well as the smaller Politifact and Gossipcop benchmarks, by applying transfer learning and a consistent preprocessing strategy for images and tokenized text. DeBERTNeXT surpassed prior multimodal baselines in performance, yielding accuracy increases of approximately 3.8% on Fakeddit, 2.1% on Politifact, and 1.0% on Gossipcop. The research concludes that pairing advanced, contemporary backbones for language and vision results in more effective multimodal fake news detection and proposes extending this approach to modalities such as audio and video.