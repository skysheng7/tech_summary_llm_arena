This article uses a lighthearted approach to point out the recurring statistical and reporting errors that The BMJ's editorial team, particularly during the busy Christmas period, frequently finds in submitted manuscripts. The piece frames these common problems as "12 days of Christmas," beginning with the critical need to precisely articulate the research inquiry and the quantity to be estimated. It underscores the importance of focusing on the magnitude of effects and their associated uncertainty (confidence intervals) and practical significance, rather than solely on P-values.

The summary further details prevalent methodological errors, including the improper management of missing data, the problematic conversion of continuous data into binary categories, the erroneous assumption of linear associations when non-linear ones might exist, and unsupported assertions regarding differences within subgroups. Additionally, it cautions against neglecting to account for clustered data, misinterpreting measures of variability in meta-analyses such as IÂ², and excessive use of meta-regression. The article also addresses the insufficient evaluation of predictive models, particularly concerning their accuracy in predicting outcomes and the issue of models fitting the observed data too closely (overfitting).

Concluding, the authors strongly advise researchers to verify their underlying assumptions through sensitivity analyses, to refrain from dubious methods of selecting variables, to adhere to established reporting standards like CONSORT, STROBE, PRISMA, and TRIPOD, and to avoid exaggerating their findings or presenting them in a misleading way.