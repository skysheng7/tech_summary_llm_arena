Framed as a holiday-themed advisory for researchers, this article from The BMJ outlines twelve recurring statistical mistakes that the journal's statistical editors frequently identify during the peer-review process.

These twelve crucial pieces of advice include: (1) precisely defining research queries and the quantities to be estimated; (2) prioritizing the presentation of estimates and their confidence intervals over sole reliance on p-values; (3) managing missing data in a suitable manner; (4) refraining from converting continuous variables into categorical ones; (5) exploring the possibility of non-linear associations; (6) measuring and reporting variations in results across subgroups; (7) addressing situations where data are clustered; (8) interpreting metrics like IÂ² and the outcomes of meta-regression correctly; (9) evaluating the accuracy of calibration within predictive models; (10) thoughtfully selecting variables for analysis; (11) examining how statistical assumptions affect outcomes; and (12) adhering to reporting standards and preventing exaggerated interpretations of findings.

The authors highlight that achieving statistical significance does not automatically imply clinical importance, and they caution that "absence of evidence is not evidence of absence." They strongly advocate for thorough reporting practices, emphasizing the use of established frameworks such as CONSORT, STROBE, PRISMA, and TRIPOD.

The ultimate goal of this paper is to assist researchers in navigating common statistical challenges and to alleviate the workload for statistical reviewers, particularly during the busy Christmas season when manuscript submissions tend to increase.