The authors of LightGCN contend that typical Graph Convolutional Network (GCN) elements, such as feature transformations and non-linear activation functions, are not only superfluous but potentially detrimental to collaborative filtering tasks when applied to graphs representing user-item interactions. Their research, based on systematic removal of components from the NGCF model, demonstrates that eliminating these operations enhances both the training process and the accuracy of recommendations. This suggests that the initial NGCF model was more complex to optimize than required. Consequently, they introduce LightGCN, a model that retains solely the neighborhood aggregation mechanism with normalized linear propagation. User and item representations in LightGCN are generated as a weighted sum of embeddings derived from all propagation layers. When trained using a standard BPR ranking loss, LightGCN achieves a parameter complexity similar to that of matrix factorization techniques. However, it excels at capturing more intricate, higher-order connections within the graph and circumvents the issue of oversmoothing by combining information from multiple layers. Empirical evaluations conducted on the Gowalla, Yelp2018, and Amazon-Book datasets reveal consistent and significant performance improvements over NGCF and other strong baseline models, with an average relative gain of approximately 16%. Further analysis connects LightGCN to simplified GCN architectures and a propagation method resembling personalized PageRank.