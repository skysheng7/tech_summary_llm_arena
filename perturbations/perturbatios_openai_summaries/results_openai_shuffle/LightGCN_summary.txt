Here's the reordered summary with the original sentences:

LightGCN argues that common GCN components like feature transformations and nonlinear activations are unnecessary—and can even hurt performance—for collaborative filtering on user–item interaction graphs. Through controlled ablation studies on NGCF, the authors show that removing these operations improves both training behavior and recommendation accuracy, suggesting the original model is harder to optimize than needed. They propose LightGCN, which keeps only neighborhood aggregation with normalized linear propagation, and forms final user/item representations by a weighted sum of embeddings from all propagation layers. Trained with a standard BPR ranking loss, LightGCN has parameter complexity comparable to matrix factorization but better captures higher-order connectivity while mitigating oversmoothing via layer combination. Experiments on Gowalla, Yelp2018, and Amazon-Book show consistent, substantial gains over NGCF and strong baselines (around ~16% average relative improvement), along with analyses linking LightGCN to simplified GCN and personalized PageRank-style propagation.